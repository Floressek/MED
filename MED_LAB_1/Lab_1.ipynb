{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analiza danych Facebooka w latach 2008-2022\n",
    "\n",
    "## Cel projektu\n",
    "Celem projektu jest analiza i modelowanie kluczowych wskaźników biznesowych Facebooka, w tym:\n",
    "1. Liczby użytkowników w czasie\n",
    "2. Zależności między przychodami a liczbą użytkowników\n",
    "3. Relacji między kosztami a zatrudnieniem\n",
    "4. Wielowymiarowego modelu kosztów\n",
    "\n",
    "## Struktura analizy\n",
    "1. Przygotowanie i eksploracja danych (2008-2017)\n",
    "2. Budowa modeli predykcyjnych\n",
    "3. Walidacja modeli na danych testowych (2018-2022)\n",
    "4. Analiza błędów i ocena jakości modeli\n",
    "\n",
    "## Wykorzystane metody\n",
    "- Regresja liniowa\n",
    "- Transformacja logarytmiczna danych\n",
    "- Analiza szeregów czasowych\n",
    "- Modelowanie wielowymiarowe"
   ],
   "id": "cb7d3bebe0b73e99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import paczek potrzebnych do laboratorium",
   "id": "6529bab4f5001d51"
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {},
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Obliczanie przedziału ufności\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acca8714116390f8",
   "metadata": {},
   "source": [
    "## Liczba uzytkownikow w kolejnych kwartalach (Facebook)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d5c6d56cc388384",
   "metadata": {},
   "source": [
    "user_count_q = {\n",
    "    'Q':\n",
    "        ['Q3 08', 'Q1 09', 'Q2 09', 'Q3 09', 'Q4 09', 'Q1 10',\n",
    "         'Q2 10', 'Q3 10', 'Q4 10', 'Q1 11', 'Q2 11', 'Q3 11',\n",
    "         'Q4 11', 'Q1 12', 'Q2 12', 'Q3 12', 'Q4 12', 'Q1 13',\n",
    "         'Q2 13', 'Q3 13', 'Q4 13', 'Q1 14', 'Q2 14', 'Q3 14',\n",
    "         'Q4 14', 'Q1 15', 'Q2 15', 'Q3 15', 'Q4 15', 'Q1 16',\n",
    "         'Q2 16', 'Q3 16', 'Q4 16', 'Q1 17', 'Q2 17', 'Q3 17', 'Q4 17'],\n",
    "    'User count':\n",
    "        [100, 197, 242, 305, 360, 431, 482, 550, 608, 680, 739, 800,\n",
    "         845, 901, 955, 1007, 1056, 1110, 1155, 1189, 1228, 1276, 1317,\n",
    "         1350, 1393, 1441, 1490, 1545, 1591, 1654, 1712, 1788, 1860, 1936,\n",
    "         2006, 2072, 2129]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7146dfa0a99984d",
   "metadata": {},
   "source": [
    "## Liczba uzytkownikow w kolejnych kwartalach (Facebook) - dane z lat 2008-2017 - usuwanie roku 2007 gdyz nie ma danych dla poprzedniej tabeli z tego roku\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "9c1b7d573154614d",
   "metadata": {},
   "source": [
    "fb_stats_y_old = {\n",
    "    'Y': [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017],\n",
    "    'Income': [153, 272, 777, 1974, 3711, 5089, 7872, 12466, 17928, 27638, 40653],\n",
    "    'Profit': [-138, -56, 229, 606, 1000, 53, 1500, 2940, 3688, 10217, 15934],\n",
    "    'Employment': [450, 850, 1218, 2127, 3200, 4619, 6337, 9199, 12691, 17048, 25105]\n",
    "}\n",
    "\n",
    "# Poprawione dane z 2008-2017\n",
    "fb_stats_y = {\n",
    "    'Y': [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017],\n",
    "    'Income': [272, 777, 1974, 3711, 5089, 7872, 12466, 17928, 27638, 40653],\n",
    "    'Profit': [-56, 229, 606, 1000, 53, 1500, 2940, 3688, 10217, 15934],\n",
    "    'Employment': [850, 1218, 2127, 3200, 4619, 6337, 9199, 12691, 17048, 25105]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b13b9012e8ec71e",
   "metadata": {},
   "source": [
    "## Tworzenie DataFrame z danymi "
   ]
  },
  {
   "cell_type": "code",
   "id": "f2880c5402c900b7",
   "metadata": {},
   "source": [
    "user_count_df = pd.DataFrame(data=user_count_q)\n",
    "fb_stats_y_df = pd.DataFrame(data=fb_stats_y)\n",
    "print(fb_stats_y_df)\n",
    "print(user_count_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dcc39ef449e524ef",
   "metadata": {},
   "source": [
    "def convert_quarter_to_year(quarter) -> int:\n",
    "    year_str = quarter.split(' ')[1]\n",
    "    year_int = 2000 + int(year_str)\n",
    "    return year_int\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7c9893bff100381",
   "metadata": {},
   "source": [
    "user_count_y_df = user_count_df.copy()\n",
    "user_count_y_df['Q'] = user_count_df['Q'].map(convert_quarter_to_year)\n",
    "# Alternatywa byloby zaladowanie danych z Q4 jako max tez dobrze\n",
    "user_count_y_df = user_count_y_df\n",
    "user_count_y_df = user_count_y_df.groupby('Q', as_index=False).max()\n",
    "user_count_y_df.rename(columns={'Q': 'Y'}, inplace=True)\n",
    "print(user_count_y_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13c1abecc3b948c5",
   "metadata": {},
   "source": [
    "fb_stats_y_df = pd.DataFrame(data=fb_stats_y)\n",
    "# Calculate costs\n",
    "fb_stats_y_df['Costs'] = fb_stats_y_df['Income'] - fb_stats_y_df['Profit']\n",
    "# fb_stats_y_df.drop([0], inplace=True)\n",
    "fb_stats_y_df.reset_index(drop=True, inplace=True)\n",
    "fb_stats_y_df.insert(3, 'User count', user_count_y_df['User count'])\n",
    "print(fb_stats_y_df)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb0e0f0ee024f1ec",
   "metadata": {},
   "source": [
    "## Tworzenie wykresu iloczynu kartezjanskiego w celu wyzanczeniach zaleznosci miedzy danymi"
   ]
  },
  {
   "cell_type": "code",
   "id": "c9b772f580da550d",
   "metadata": {},
   "source": [
    "pd.plotting.scatter_matrix(fb_stats_y_df, figsize=(10, 10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "92f0ee58fbf0409",
   "metadata": {},
   "source": [
    "## Dane dla przyszlych lat (2018-2022) potrzbne do weryfikowania predyckji modelu"
   ]
  },
  {
   "cell_type": "code",
   "id": "f860b75ee635c2cb",
   "metadata": {
    "tags": [
     "Dane pobrane"
    ]
   },
   "source": [
    "user_count_q_test = {\n",
    "    'Q':\n",
    "        ['Q1 18', 'Q2 18', 'Q3 18', 'Q4 18',\n",
    "         'Q1 19', 'Q2 19', 'Q3 19', 'Q4 19',\n",
    "         'Q1 20', 'Q2 20', 'Q3 20', 'Q4 20',\n",
    "         'Q1 21', 'Q2 21', 'Q3 21', 'Q4 21',\n",
    "         'Q1 22', 'Q2 22', 'Q3 22', 'Q4 22'],\n",
    "    'User count':\n",
    "        [2196, 2234, 2271, 2320, 2375, 2414, 2449, 2498, 2603, 2701, 2740, 2797,\n",
    "         2853, 2895, 2910, 2912, 2936, 2934, 2958, 2963]\n",
    "}\n",
    "\n",
    "fb_stats_y_test = {\n",
    "    'Y': [2018, 2019, 2020, 2021, 2022],\n",
    "    'Income': [55838, 70697, 85965, 117929, 116609],\n",
    "    'Profit': [22112, 18485, 29146, 39370, 23200],\n",
    "    'Costs': [33726, 52212, 56819, 78559, 93409],\n",
    "    'Employment': [35587, 44942, 58604, 71970, 87314],\n",
    "    'User count': [2320, 2498, 2797, 2912, 2963]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5ce1e04605ebbc7b",
   "metadata": {},
   "source": [
    "user_count_test_df = pd.DataFrame(data=user_count_q_test)\n",
    "fb_stats_y_test_df = pd.DataFrame(data=fb_stats_y_test)\n",
    "print(user_count_test_df)\n",
    "print(fb_stats_y_test_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f88cea006ccaba3c",
   "metadata": {},
   "source": [
    "## Funkcja do obliczania statystyki modelu"
   ]
  },
  {
   "cell_type": "code",
   "id": "c58f822af7fb255d",
   "metadata": {
    "tags": [
     "Explanation - errors"
    ]
   },
   "source": [
    "def calculate_model_stats(y_hat, y_true, X) -> dict:\n",
    "    # Dodajemy kolumne jedynek dla wyrazu wolnego \n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "\n",
    "    residuals = y_true - y_hat\n",
    "    # Obliczamy sume kwadratow reszt(RSS - Residual Sum of Squares)\n",
    "    # RSS = e^T * e, gdzie e to wektor reszt\n",
    "    residuals_sum_squared = residuals.T @ residuals\n",
    "\n",
    "    # Obliczamy estymator wariancji resztowej (σ²)\n",
    "    # σ² = RSS/(n-k), gdzie:\n",
    "    # n = liczba obserwacji (y_hat.shape[0])\n",
    "    # k = liczba parametrów modelu (X.shape[1])\n",
    "    standard_variance = residuals_sum_squared[0, 0] / (y_hat.shape[0] - X.shape[1])\n",
    "\n",
    "    # Var(β̂) = σ² × (X^T × X)^(-1)\n",
    "    model_coefficients_covariance = standard_variance * np.linalg.inv(X.T @ X)  # Liczymy macierz kowariancji wspl. modelu\n",
    "    stats = dict()\n",
    "\n",
    "    # Obliczamy błędy standardowe dla każdego współczynnika\n",
    "    # SE(β̂ᵢ) = √Var(β̂ᵢ)\n",
    "    for number in range(model_coefficients_covariance.shape[0]):\n",
    "        stats['Standard error a' + str(number)] = np.sqrt(model_coefficients_covariance[number, number])\n",
    "\n",
    "    # Na koniec blad standardowy modelu\n",
    "    stats['Standard error e'] = np.sqrt(standard_variance)\n",
    "    return stats\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funkcje pomocnicze dla oceny predykcji modelu MSE, RMSE MAE i MAPE",
   "id": "a49585deed60c7ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_prediction_metrics(y_true, y_pred):\n",
    "    # Parametry funkcji: y_true - rzeczywiste wartości, y_pred - przewidywane wartości\n",
    "    # Konwersja do numpy array dla pewności\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    \n",
    "    # Mean Squared Error (MSE)\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    # Root Mean Squared Error (RMSE)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    \n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    # R-squared (R²)\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'R2': r2\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics, model_name=\"Model\"):\n",
    "    def get_error_rating(metric_name, value):\n",
    "        if metric_name == 'MAPE':\n",
    "            if value < 10: return \"Bardzo dobry\"\n",
    "            elif value < 20: return \"Dobry\"\n",
    "            elif value < 30: return \"Umiarkowany\"\n",
    "            else: return \"Słaby\"\n",
    "        elif metric_name == 'R2':\n",
    "            if value > 0.9: return \"Bardzo dobry\"\n",
    "            elif value > 0.7: return \"Dobry\"\n",
    "            elif value > 0.5: return \"Umiarkowany\"\n",
    "            else: return \"Słaby\"\n",
    "        return \"\"  # dla pozostałych metryk nie wyświetlamy oceny\n",
    "\n",
    "    def get_unit(metric_name):\n",
    "        units = {\n",
    "            'MSE': '(jednostka²)',\n",
    "            'RMSE': '(jednostka)',\n",
    "            'MAE': '(jednostka)',\n",
    "            'MAPE': '%',\n",
    "            'R2': '(0-1)'\n",
    "        }\n",
    "        return units.get(metric_name, '')\n",
    "\n",
    "    print(f\"\\nMetryki oceny dla {model_name}:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Metryka':<10} {'Wartość':<15} {'Jednostka':<15} {'Ocena':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        unit = get_unit(metric)\n",
    "        rating = get_error_rating(metric, value)\n",
    "        print(f\"{metric:<10} {value:>15.4f} {unit:<15} {rating:<15}\")\n",
    "        \n",
    "        \n",
    "def print_metrics_with_specific_units(metrics, model_name=\"Model\", unit_name=\"\"):\n",
    "    def get_error_rating(metric_name, value):\n",
    "        if metric_name == 'MAPE':\n",
    "            if value < 10: return \"Bardzo dobry\"\n",
    "            elif value < 20: return \"Dobry\"\n",
    "            elif value < 30: return \"Umiarkowany\"\n",
    "            else: return \"Słaby\"\n",
    "        elif metric_name == 'R2':\n",
    "            if value > 0.9: return \"Bardzo dobry\"\n",
    "            elif value > 0.7: return \"Dobry\"\n",
    "            elif value > 0.5: return \"Umiarkowany\"\n",
    "            else: return \"Słaby\"\n",
    "        return \"\"\n",
    "\n",
    "    def get_unit(metric_name, unit_name):\n",
    "        units = {\n",
    "            'MSE': f\"({unit_name}²)\",\n",
    "            'RMSE': f\"({unit_name})\",\n",
    "            'MAE': f\"({unit_name})\",\n",
    "            'MAPE': '%',\n",
    "            'R2': '(0-1)'\n",
    "        }\n",
    "        return units.get(metric_name, '')\n",
    "\n",
    "    print(f\"\\nMetryki oceny dla {model_name}:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Metryka':<10} {'Wartość':<15} {'Jednostka':<20} {'Ocena':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        unit = get_unit(metric, unit_name)\n",
    "        rating = get_error_rating(metric, value)\n",
    "        print(f\"{metric:<10} {value:>15.4f} {unit:<20} {rating:<15}\")"
   ],
   "id": "226c20a4147811d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3de7a629c721ff54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T19:16:12.673553Z",
     "start_time": "2024-11-12T19:16:12.669111Z"
    }
   },
   "source": [
    "## Funkcje pomocnicze dla szeregow czasowych z uzyciem kwartalow"
   ]
  },
  {
   "cell_type": "code",
   "id": "29aa088a4a7e1903",
   "metadata": {},
   "source": [
    "def transform_quarter_to_number(string) -> int:\n",
    "    if ' ' not in string:\n",
    "        raise ValueError(f\"Invalid format for quarter: {string}\")\n",
    "    quarter, year = string.split(' ')\n",
    "    quarters = {'Q1': 0, 'Q2': 1, 'Q3': 2, 'Q4': 3}\n",
    "    year = int(year) - 8\n",
    "    return year * 4 + quarters[quarter]\n",
    "\n",
    "\n",
    "def transform_number_to_quarter(number) -> str:\n",
    "    year = (number // 4) + 8\n",
    "    quarters = {0: 'Q1', 1: 'Q2', 2: 'Q3', 3: 'Q4'}\n",
    "    quarter = quarters[number % 4]\n",
    "    quarter_string = quarter + ' {:02d}'.format(year)\n",
    "    return quarters[quarter] + ' ' + str(year)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a212ab7500b1fd9",
   "metadata": {},
   "source": [
    "user_count_df['Q'] = user_count_df['Q'].astype(str).map(transform_quarter_to_number)\n",
    "user_count_test_df['Q'] = user_count_test_df['Q'].astype(str).map(transform_quarter_to_number)\n",
    "print(user_count_df)\n",
    "print(user_count_test_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f5ae2273fd08b2a5",
   "metadata": {},
   "source": [
    "## Trenowanie modelu szeregu czasowego "
   ]
  },
  {
   "cell_type": "code",
   "id": "7a335bf9a82ebc80",
   "metadata": {},
   "source": [
    "R_train = user_count_df['Q'].to_numpy().reshape(-1, 1)\n",
    "U_train = user_count_df['User count'].to_numpy().reshape(-1, 1)\n",
    "R_test = user_count_test_df['Q'].to_numpy().reshape(-1, 1)\n",
    "U_test = user_count_test_df['User count'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(R_train, U_train)\n",
    "\n",
    "# Ocena modelu na danych testowych\n",
    "train_metrics_0 = calculate_prediction_metrics(U_train, linear_regression.predict(R_train))\n",
    "test_metrics_0 = calculate_prediction_metrics(U_test, linear_regression.predict(R_test))\n",
    "\n",
    "print_metrics(train_metrics_0, \"Model szeregu czasowego (dane treningowe)\")\n",
    "print_metrics(test_metrics_0, \"Model szeregu czasowego (dane testowe)\")\n",
    "\n",
    "print(linear_regression)\n",
    "\n",
    "print(f'User count R^2: {linear_regression.score(R_train, U_train):}')\n",
    "print(f\"Model: U = {linear_regression.intercept_[0]:} + {linear_regression.coef_[0][0]:} * R\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4bcf767553946365",
   "metadata": {},
   "source": "## Errors for out model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "errors = calculate_model_stats(linear_regression.predict(R_train), U_train, R_train)\n",
    "# print(errors)\n",
    "\n",
    "print(\"Errors for model:\")\n",
    "for key, value in errors.items():\n",
    "    print(f\"{key}: {float(value):.4f}\")"
   ],
   "id": "e743760c18830136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wizualizacja modelu szeregu czasowego",
   "id": "e153d13d74e488ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Funckja zmieniona w celu lepszej czytelnosci\n",
    "def transform_number_to_quarter_custom(number) -> str:\n",
    "    quarters = {0: 'Q1', 1: 'Q2', 2: 'Q3', 3: 'Q4'}\n",
    "    year = 2008 + (number // 4)\n",
    "    quarter = quarters[number % 4]\n",
    "    return f'{quarter} {year}'\n",
    "\n",
    "\n",
    "# Przygotowanie danych\n",
    "train_predictions = linear_regression.predict(R_train)\n",
    "test_predictions = linear_regression.predict(R_test)\n",
    "\n",
    "# Obliczanie przedziału ufności\n",
    "mse = mean_squared_error(U_train, train_predictions)\n",
    "std_dev = np.sqrt(mse)\n",
    "confidence_interval = 1.96 * std_dev  # 95% przedział ufności\n",
    "\n",
    "# Tworzenie wykresu z większym rozmiarem i lepszymi proporcjami\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "\n",
    "# Konfiguracja stylu\n",
    "plt.style.use('seaborn-v0_8-deep')\n",
    "colors = {\n",
    "    'train_dots': '#1f77b4',\n",
    "    'train_line': '#ff0000',\n",
    "    'test_dots': '#2ca02c',\n",
    "    'test_line': '#ff7f0e',\n",
    "    'confidence': '#fff59d'\n",
    "}\n",
    "\n",
    "# Dane treningowe\n",
    "plt.scatter(R_train, U_train, color=colors['train_dots'], alpha=0.7, s=60,\n",
    "            label='Rzeczywista liczba użytkowników (dane uczące)',\n",
    "            edgecolor='white', linewidth=1)\n",
    "plt.plot(R_train, train_predictions, color=colors['train_line'], linewidth=2.5,\n",
    "         label='Prognozowana liczba użytkowników (dane uczące)')\n",
    "\n",
    "# Dane testowe\n",
    "plt.scatter(R_test, U_test, color=colors['test_dots'], alpha=0.7, s=60,\n",
    "            label='Rzeczywista liczba użytkowników (dane testowe)',\n",
    "            edgecolor='white', linewidth=1)\n",
    "plt.plot(R_test, test_predictions, color=colors['test_line'], linewidth=2.5,\n",
    "         label='Prognozowana liczba użytkowników (dane testowe)')\n",
    "\n",
    "# Przedział ufności z lepszą przezroczystością i kolorem\n",
    "all_quarters = np.concatenate([R_train.flatten(), R_test.flatten()])\n",
    "all_predictions = np.concatenate([train_predictions.flatten(), test_predictions.flatten()])\n",
    "plt.fill_between(\n",
    "    all_quarters,\n",
    "    all_predictions - confidence_interval,\n",
    "    all_predictions + confidence_interval,\n",
    "    color=colors['confidence'],\n",
    "    alpha=0.3,\n",
    "    label='95% przedział ufności'\n",
    ")\n",
    "\n",
    "# Formatowanie osi i etykiet\n",
    "plt.xlabel('Kwartał', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Liczba użytkowników [mln]', fontsize=12, fontweight='bold')\n",
    "plt.title('Prognoza liczby użytkowników Facebooka w latach 2008-2022',\n",
    "          fontsize=16, pad=20, fontweight='bold')\n",
    "\n",
    "# Generowanie etykiet osi X używając zdefiniowanych funkcji\n",
    "x_ticks = range(0, 60)\n",
    "x_labels = [transform_number_to_quarter_custom(q) for q in x_ticks]\n",
    "plt.xticks(x_ticks, x_labels, rotation=45, ha='right')\n",
    "\n",
    "# Dodanie siatki z lepszą widocznością\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Lepsze umiejscowienie legendy i dodanie ramki\n",
    "legend = plt.legend(bbox_to_anchor=(1.15, 1), loc='upper left',\n",
    "                    frameon=True, fancybox=True, shadow=True)\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "# Dodanie informacji o R² w lepszym formacie\n",
    "r2_score = linear_regression.score(R_train, U_train)\n",
    "stats_text = f'R² (test) = {r2_score:.4f}\\n'\n",
    "stats_text += f'RMSE = {np.sqrt(mse):.2f} mln'\n",
    "\n",
    "plt.text(0.02, 0.95, stats_text,\n",
    "         transform=plt.gca().transAxes,\n",
    "         bbox=dict(facecolor='white',\n",
    "                   edgecolor='gray',\n",
    "                   alpha=0.8,\n",
    "                   boxstyle='round,pad=0.5'),\n",
    "         fontsize=10)\n",
    "\n",
    "# Dodanie adnotacji dla ważnych punktów\n",
    "max_users_idx = np.argmax(U_test)\n",
    "plt.annotate(f'Maksimum: {U_test[max_users_idx][0]:.0f} mln',\n",
    "             xy=(R_test[max_users_idx], U_test[max_users_idx]),\n",
    "             xytext=(10, 10), textcoords='offset points',\n",
    "             bbox=dict(facecolor='white', edgecolor='gray', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "# Dostosowanie układu i marginesów \n",
    "plt.tight_layout()\n",
    "\n",
    "# Pokazanie wykresu\n",
    "plt.show()"
   ],
   "id": "5d7adc20fe017545",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wykres income w zaleznosci od user_count",
   "id": "58608e97fd31e960"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przygotowanie danych treningowych (2008-2017)\n",
    "X_train = fb_stats_y_df['User count'].to_numpy().reshape(-1, 1)  # zmienna niezależna\n",
    "y_train = fb_stats_y_df['Income'].to_numpy().reshape(-1, 1)      # zmienna zależna\n",
    "\n",
    "# Przygotowanie danych testowych (2018-2022)\n",
    "X_test = fb_stats_y_test_df['User count'].to_numpy().reshape(-1, 1)\n",
    "y_test = fb_stats_y_test_df['Income'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Trenowanie modelu\n",
    "linear_regression_income = LinearRegression()\n",
    "linear_regression_income.fit(X_train, y_train)  # X_train jako pierwsza zmienna"
   ],
   "id": "ff11939963b3f64f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Statystyki modelu: wspolczynnik determinacji R^2\n",
    "print(f'Income R^2: {linear_regression_income.score(X_train, y_train):}')\n",
    "\n",
    "# Równanie modelu ma postać: I = wyraz wolny + współczynnik * U\n",
    "# - 'intercept_' to wyraz wolny (przecięcie z osią y) linii regresji, reprezentujący przewidywaną wartość I, gdy U wynosi 0.\n",
    "# - 'coef_' to nachylenie linii regresji, wskazujące, o ile zmienia się I przy jednostkowej zmianie U.\n",
    "print(\n",
    "    f'Model: I {linear_regression_income.intercept_[0]:} + {linear_regression_income.coef_[0][0]:} * U')  # Model rowna sie wspolczynnikowi nachylenia + wyrazowi wolnemu"
   ],
   "id": "d21b56c52ab494d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Błędy modelu",
   "id": "c8dad2cf9ac7e8a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przeliczanie błędów modelu\n",
    "errors = calculate_model_stats(linear_regression_income.predict(X_train), y_train, X_train)\n",
    "# print(errors)\n",
    "\n",
    "print(\"Errors for model:\")\n",
    "for key, value in errors.items():\n",
    "    print(f\"{key}: {float(value):.4f}\")"
   ],
   "id": "aa698b4b07eb6c52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przewidywania dla danych treningowych\n",
    "train_predictions = linear_regression_income.predict(X_train)\n",
    "print(\"Przewidywania dla danych treningowych:\")\n",
    "print(train_predictions)\n",
    "print(\"\\n\" + \"=\" * 30 + \"\\n\")  # Separator dla lepszej czytelności\n",
    "\n",
    "# Przewidywania dla danych testowych\n",
    "test_predictions = linear_regression_income.predict(X_test)\n",
    "print(\"Przewidywania dla danych testowych:\")\n",
    "print(test_predictions)"
   ],
   "id": "9cc0a421bde8b668",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Zmiana koncepcji testowanie modelu dla usunietych 3 pierwszych danych dla mniej problematycznej prostej",
   "id": "669d92d245b6a84f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przygotowanie danych treningowych i testowych\n",
    "# U_train_1 i P_train_1 zawierają wszystkie dane, podczas gdy U_train_2 i P_train_2 pomijają pierwsze trzy punkty\n",
    "U_train_1 = fb_stats_y_df['User count'].to_numpy().reshape(-1, 1)\n",
    "P_train_1 = fb_stats_y_df['Income'].to_numpy().reshape(-1, 1)\n",
    "P_train_log_1 = np.log10(P_train_1)  # Logarytmowanie przychodów dla lepszej liniowości\n",
    "\n",
    "# Narysuj wykresy dla obu zestawów danych\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.scatter(U_train_1, P_train_log_1, label='Przychód rzeczywisty')\n",
    "plt.xlabel('Liczba użytkowników [mln]')\n",
    "plt.ylabel('Przychód [mln]')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.scatter(U_train_1, P_train_1, label='Przychód rzeczywisty')\n",
    "plt.xlabel('Liczba użytkowników [mln]')\n",
    "plt.ylabel('Przychód [mln]')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "48565b6988974553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logarytmizacja danych oraz testowanie modelu liniowej regresji dla zadanych punktow",
   "id": "414c980ce3447876"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przygotowanie danych treningowych i testowych\n",
    "U_train_1 = fb_stats_y_df['User count'].to_numpy().reshape(-1, 1)\n",
    "P_train_1 = fb_stats_y_df['Income'].to_numpy().reshape(-1, 1)\n",
    "P_train_log_1 = np.log10(P_train_1)  # Logarytmowanie przychodów dla lepszej liniowości\n",
    "\n",
    "# Ile punktów chcemy usunąć\n",
    "points_to_remove = 3\n",
    "\n",
    "# Wydzielenie usuniętych punktów i pozostałych\n",
    "U_removed = U_train_1[:points_to_remove]  # Pierwsze 3 punkty\n",
    "P_removed_log = P_train_log_1[:points_to_remove]  # Logarytmy pierwszych 3 punktów\n",
    "U_kept = U_train_1[points_to_remove:]  # Pozostałe punkty\n",
    "P_kept_log = P_train_log_1[points_to_remove:]  # Logarytmy pozostałych punktów\n",
    "\n",
    "# Tworzenie i trenowanie modeli regresji liniowej\n",
    "l1 = LinearRegression()\n",
    "l1.fit(U_train_1, P_train_log_1)  # Model uwzględniający wszystkie punkty\n",
    "\n",
    "l2 = LinearRegression()\n",
    "l2.fit(U_kept, P_kept_log)  # Model pomijający pierwsze trzy punkty\n",
    "\n",
    "# Pobieranie współczynników i wyrazów wolnych z obu modeli\n",
    "a11 = l1.coef_[0]\n",
    "a01 = l1.intercept_\n",
    "a12 = l2.coef_[0]\n",
    "a02 = l2.intercept_\n",
    "\n",
    "# Przewidywanie przychodów na podstawie obu modeli\n",
    "P_pred_1 = a11 * U_train_1 + a01\n",
    "P_pred_2 = a12 * U_train_1 + a02\n",
    "\n",
    "# Wizualizacja danych i modeli\n",
    "plt.clf()\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Punkty zachowane na zielono\n",
    "plt.scatter(U_kept, P_kept_log, color='green', label='Punkty zachowane')\n",
    "# Punkty usunięte na czerwono\n",
    "plt.scatter(U_removed, P_removed_log, color='red', label='Punkty usunięte')\n",
    "\n",
    "plt.plot(U_train_1, P_pred_1, label='Linia uwzględniająca wszystkie punkty')\n",
    "plt.plot(U_train_1, P_pred_2, label='Linia bez 3 pierwszych punktów')\n",
    "\n",
    "plt.xlabel('Liczba użytkowników [mln]')\n",
    "plt.ylabel('Przychód [log10(mln)]')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f'Model: I {l2.intercept_[0]:} + {l2.coef_[0][0]:} * U')  # Model rowna sie wspolczynnikowi nachylenia + wyrazowi wolnemu"
   ],
   "id": "2c6a260f902fa106",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bledy modelu",
   "id": "1535982cd619dabd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przygotowanie danych do ostatecznego modelu\n",
    "U_train = fb_stats_y_df['User count'].to_numpy()[3:].reshape(-1, 1)\n",
    "P_train = fb_stats_y_df['Income'].to_numpy()[3:].reshape(-1, 1)\n",
    "P_train_log = np.log10(P_train)\n",
    "\n",
    "U_test = fb_stats_y_test_df['User count'].to_numpy().reshape(-1, 1)\n",
    "P_test = fb_stats_y_test_df['Income'].to_numpy().reshape(-1, 1)\n",
    "P_test_log = np.log10(P_test)\n",
    "\n",
    "# Trenowanie ostatecznego modelu regresji liniowej\n",
    "lin_reg_income = LinearRegression()\n",
    "lin_reg_income.fit(U_train, P_train_log)\n",
    "\n",
    "# Ocena modelu\n",
    "print(f'Income R^2: {lin_reg_income.score(U_train, P_train_log)}')\n",
    "errors = calculate_model_stats(lin_reg_income.predict(U_train), P_train_log, U_train)\n",
    "print(\"Errors for model:\")\n",
    "for key, value in errors.items():\n",
    "    print(f\"{key}: {float(value):.4f}\")\n",
    "    \n",
    "# print(errors) # For the a1 bc -05e\n",
    "P_error = errors['Standard error e']\n",
    "\n",
    "# Ocena modelu na danych zlogarytmowanych\n",
    "train_metrics_1 = calculate_prediction_metrics(P_train_log, lin_reg_income.predict(U_train))\n",
    "test_metrics_1 = calculate_prediction_metrics(P_test_log, lin_reg_income.predict(U_test))\n",
    "\n",
    "print_metrics_with_specific_units(train_metrics_1, \"Model przychodów zlogarytmowanych (dane treningowe)\", \"log10(mln $)\")\n",
    "print_metrics_with_specific_units(test_metrics_1, \"Model przychodów zlogarytmowanych (dane testowe)\", \"log10(mln $)\")"
   ],
   "id": "52296acbc8663409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wizualizacja modelu",
   "id": "d397a790e3f8d04e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pobieranie współczynników i wyrazu wolnego z ostatecznego modelu\n",
    "a1 = lin_reg_income.coef_[0]\n",
    "a0 = lin_reg_income.intercept_\n",
    "\n",
    "# Przewidywanie przychodów dla danych treningowych i testowych\n",
    "P_train_pred = a1 * U_train + a0\n",
    "P_test_pred = a1 * U_test + a0\n",
    "\n",
    "# Wizualizacja wyników modelu\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Dodanie siatki z lepszą widocznością\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.fill_between(U_train.reshape(-1), \n",
    "                 (P_train_pred - P_error).reshape(-1), \n",
    "                 (P_train_pred + P_error).reshape(-1), \n",
    "                 color='yellow', \n",
    "                 label='Odchylenie standardowe prognozy (dane uczące)')\n",
    "plt.fill_between(U_test.reshape(-1), \n",
    "                 (P_test_pred - P_error).reshape(-1), \n",
    "                 (P_test_pred + P_error).reshape(-1), \n",
    "                 color='yellow', \n",
    "                 alpha=0.5, \n",
    "                 label='Odchylenie standardowe prognozy (dane testowe)')\n",
    "plt.scatter(U_train, P_train_log, label=\"Przychód prawdziwy (dane uczące)\")\n",
    "plt.plot(U_train, P_train_pred, label='Przychód przewidywany (dane uczące)', color='red')\n",
    "plt.scatter(U_test, P_test_log, label=\"Przychód prawdziwy (dane testowe)\", color='green')\n",
    "plt.plot(U_test, P_test_pred, label='Przychód przewidywany (dane testowe)', color='orange')\n",
    "plt.ylabel('Przychód [mln]')\n",
    "plt.xlabel('Liczba użytkowników [mln]')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "1f1816bd262bd2f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wykres zależności Costs od Employment (Jak kształtują się koszty w zależności od zatrudnienia)",
   "id": "b2b097cd3ffe263b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#  Wykres zależności Costs od Employment (Jak kształtują się koszty w zależności od zatrudnienia)\n",
    "X_train = fb_stats_y_df['Employment'].to_numpy().reshape(-1, 1)\n",
    "y_train = fb_stats_y_df['Costs'].to_numpy().reshape(-1, 1)\n",
    "X_test = fb_stats_y_test_df['Employment'].to_numpy().reshape(-1, 1)\n",
    "y_test = fb_stats_y_test_df['Costs'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "linear_regression_cost = LinearRegression()\n",
    "linear_regression_cost.fit(X_train, y_train)\n",
    "\n",
    "print(linear_regression_cost)\n",
    "print(f'Cost R^2: {linear_regression_cost.score(X_train, y_train):}')\n",
    "print(f\"Model: P = {linear_regression_cost.intercept_[0]:} + {linear_regression_cost.coef_[0][0]:} * X\")\n"
   ],
   "id": "3e91ac460fbe870f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Standardowe błędy:",
   "id": "78e45fa6cea9371b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "errors = calculate_model_stats(linear_regression_cost.predict(X_train), y_train, X_train)\n",
    "# print(errors)\n",
    "\n",
    "print(\"Errors for model:\")\n",
    "for key, value in errors.items():\n",
    "    print(f\"{key}: {float(value):.4f}\")\n",
    "    \n",
    "train_metrics_2 = calculate_prediction_metrics(y_train, linear_regression_cost.predict(X_train))\n",
    "test_metrics_2 = calculate_prediction_metrics(y_test, linear_regression_cost.predict(X_test))\n",
    "\n",
    "print_metrics_with_specific_units(train_metrics_2, \"Model kosztów vs zatrudnienie (dane treningowe)\", \"mln $\")\n",
    "print_metrics_with_specific_units(test_metrics_2, \"Model kosztów vs zatrudnienie (dane testowe)\", \"mln $\")"
   ],
   "id": "4166e1bdf74fe638",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Wizualizcja modelu Kosztów od Zatrudnienia:",
   "id": "8732912f32330c42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Przygotowanie danych\n",
    "train_predictions = linear_regression_cost.predict(X_train)\n",
    "test_predictions = linear_regression_cost.predict(X_test)\n",
    "\n",
    "# Obliczanie przedziału ufności\n",
    "mse = mean_squared_error(y_train, train_predictions)\n",
    "std_dev = np.sqrt(mse)\n",
    "confidence_interval = 1.96 * std_dev  # 95% przedział ufności\n",
    "\n",
    "# Tworzenie wykresu z większym rozmiarem i lepszymi proporcjami\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Konfiguracja stylu\n",
    "plt.style.use('seaborn-v0_8-deep')\n",
    "colors = {\n",
    "    'train_dots': '#1f77b4',  # Stonowany niebieski dla punktów treningowych\n",
    "    'train_line': '#ff0000',  # Ciepły czerwony dla linii treningowej\n",
    "    'test_dots': '#2ca02c',  # Łagodny zielony dla punktów testowych\n",
    "    'test_line': '#ff7f0e',  # Jasny fiolet dla linii testowej\n",
    "    'confidence': '#fff59d'  # Ciepły żółty dla przedziału ufności\n",
    "}\n",
    "\n",
    "# Dane treningowe\n",
    "plt.scatter(X_train, y_train, color=colors['train_dots'], alpha=0.7, s=60,\n",
    "            label='Rzeczywiste koszty (dane uczące)',\n",
    "            edgecolor='white', linewidth=1)\n",
    "plt.plot(X_train, train_predictions, color=colors['train_line'], linewidth=2.5,\n",
    "         label='Prognozowane koszty (dane uczące)')\n",
    "\n",
    "# Dane testowe\n",
    "plt.scatter(X_test, y_test, color=colors['test_dots'], alpha=0.7, s=60,\n",
    "            label='Rzeczywiste koszty (dane testowe)',\n",
    "            edgecolor='white', linewidth=1)\n",
    "plt.plot(X_test, test_predictions, color=colors['test_line'], linewidth=2.5,\n",
    "         label='Prognozowane koszty (dane testowe)')\n",
    "\n",
    "# Przedział ufności z lepszą przezroczystością i kolorem\n",
    "all_employment = np.concatenate([X_train.flatten(), X_test.flatten()])\n",
    "all_predictions = np.concatenate([train_predictions.flatten(), test_predictions.flatten()])\n",
    "plt.fill_between(\n",
    "    all_employment,\n",
    "    all_predictions - confidence_interval,\n",
    "    all_predictions + confidence_interval,\n",
    "    color=colors['confidence'],\n",
    "    alpha=0.3,\n",
    "    label='95% przedział ufności'\n",
    ")\n",
    "\n",
    "# Formatowanie osi i etykiet\n",
    "plt.xlabel('Liczba zatrudnień', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Koszty [mln]', fontsize=12, fontweight='bold')\n",
    "plt.title('Prognoza kosztów Facebooka w zależności od liczby zatrudnień',\n",
    "          fontsize=16, pad=20, fontweight='bold')\n",
    "\n",
    "# Dodanie siatki z lepszą widocznością\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Lepsze umiejscowienie legendy i dodanie ramki\n",
    "legend = plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n",
    "                    frameon=True, fancybox=True, shadow=True)\n",
    "legend.get_frame().set_alpha(0.9)\n",
    "\n",
    "# Dodanie informacji o R² w lepszym formacie\n",
    "r2_score = linear_regression_cost.score(X_train, y_train)\n",
    "stats_text = f'R² (test) = {r2_score:.4f}\\n'\n",
    "stats_text += f'RMSE = {np.sqrt(mse):.2f} mln'\n",
    "\n",
    "plt.text(0.02, 0.95, stats_text,\n",
    "         transform=plt.gca().transAxes,\n",
    "         bbox=dict(facecolor='white',\n",
    "                   edgecolor='gray',\n",
    "                   alpha=0.8,\n",
    "                   boxstyle='round,pad=0.5'),\n",
    "         fontsize=10)\n",
    "\n",
    "# Dodanie adnotacji dla ważnych punktów, jeśli potrzebne\n",
    "max_cost_idx = np.argmax(y_test)\n",
    "plt.annotate(f'Maksimum: {y_test[max_cost_idx][0]:.0f} mln',\n",
    "             xy=(X_test[max_cost_idx], y_test[max_cost_idx]),\n",
    "             xytext=(-50, 15), textcoords='offset points',\n",
    "             bbox=dict(facecolor='white', edgecolor='gray', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->'))\n",
    "\n",
    "# Dostosowanie układu i marginesów \n",
    "plt.tight_layout()\n",
    "\n",
    "# Pokazanie wykresu\n",
    "plt.show()"
   ],
   "id": "7b91430d6609ae57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Drugi wykres - sprawdzenie",
   "id": "425c05b456526674"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Przedział ufności dla danych uczących\n",
    "plt.fill_between(X_train.reshape(-1),\n",
    "                 (train_predictions - confidence_interval).reshape(-1),\n",
    "                 (train_predictions + confidence_interval).reshape(-1),\n",
    "                 color='yellow', label='Odchylenie standardowe prognozy')\n",
    "\n",
    "# Przedział ufności dla danych testowych\n",
    "plt.fill_between(X_test.reshape(-1),\n",
    "                 (test_predictions - confidence_interval).reshape(-1),\n",
    "                 (test_predictions + confidence_interval).reshape(-1),\n",
    "                 color='yellow')\n",
    "\n",
    "# Punkty rzeczywistych kosztów dla danych treningowych\n",
    "plt.scatter(X_train, y_train, label=\"Koszty rzeczywiste (dane uczące)\")\n",
    "\n",
    "# Linia przewidywanych kosztów dla danych treningowych\n",
    "plt.plot(X_train, train_predictions, label='Koszty przewidywane (dane uczące)', color='red')\n",
    "\n",
    "# Punkty rzeczywistych kosztów dla danych testowych\n",
    "plt.scatter(X_test, y_test, label=\"Koszty rzeczywiste (dane testowe)\", color='green')\n",
    "\n",
    "# Linia przewidywanych kosztów dla danych testowych\n",
    "plt.plot(X_test, test_predictions, label='Koszty przewidywane (dane testowe)', color='orange')\n",
    "\n",
    "# Etykiety osi\n",
    "plt.ylabel('Koszty [mln]')\n",
    "plt.xlabel('Liczba zatrudnień')\n",
    "\n",
    "# Legenda\n",
    "plt.legend()\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()\n"
   ],
   "id": "c3bed5a614ce6a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model kosztów w zależności od Zatrudnienia i Przychodu",
   "id": "a0e89199b7cd2f66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Z_train = fb_stats_y_df['Employment'].to_numpy().reshape(-1, 1)\n",
    "P_train = fb_stats_y_df['Income'].to_numpy().reshape(-1, 1)\n",
    "ZP_train = np.column_stack((Z_train, P_train))\n",
    "C_train = fb_stats_y_df['Costs'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "Z_test = fb_stats_y_test_df['Employment'].to_numpy().reshape(-1, 1)\n",
    "P_test = fb_stats_y_test_df['Income'].to_numpy().reshape(-1, 1)\n",
    "ZP_test = np.column_stack((Z_test, P_test))\n",
    "C_test = fb_stats_y_test_df['Costs'].to_numpy().reshape(-1, 1)"
   ],
   "id": "a364791f4cdf737c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_reg_costs = LinearRegression()\n",
    "linear_reg_costs.fit(ZP_train, C_train)\n",
    "\n",
    "print(f'Cost R^2: {linear_reg_costs.score(ZP_train, C_train):}')"
   ],
   "id": "51e2da173875d13d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bez logarytmizacji widzimy znaczne skoki w MSE. Spróbujmy zlogarytmizować dane i zobaczyć, czy to coś zmieni",
   "id": "7a03fc69026ef13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generowanie prognoz dla danych treningowych\n",
    "y_hat = linear_reg_costs.predict(ZP_train)\n",
    "\n",
    "# Rzeczywiste wartości kosztów (y_true)\n",
    "y_true = C_train\n",
    "\n",
    "# Macierz X dla funkcji `calculate_model_stats` - zawiera dane treningowe ZP_train\n",
    "# Ta funkcja sama doda kolumnę jedynek, więc ZP_train powinno mieć tylko zmienne objaśniające.\n",
    "X = ZP_train\n",
    "\n",
    "# Użycie funkcji calculate_model_stats\n",
    "stats = calculate_model_stats(y_hat, y_true, X)\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(\"Statystyki modelu:\", stats)\n",
    "\n",
    "train_metrics_3 = calculate_prediction_metrics(C_train, linear_reg_costs.predict(ZP_train))\n",
    "test_metrics_3 = calculate_prediction_metrics(C_test, linear_reg_costs.predict(ZP_test))\n",
    "\n",
    "print_metrics_with_specific_units(train_metrics_3, \"Model wielowymiarowy kosztów (dane treningowe)\", \"mln $\")\n",
    "print_metrics_with_specific_units(test_metrics_3, \"Model wielowymiarowy kosztów (dane testowe)\", \"mln $\")"
   ],
   "id": "527d1441e5b84a44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "# Znacznie szersze zakresy dla surface plot -> paramtry: gestosc siatki(100), zakresy osi x i y\n",
    "axis_x = np.linspace(-5000, 100000, 100)  # Zwiększony zakres dla liczby pracowników\n",
    "axis_y = np.linspace(-5000, 150000, 100)  # Zwiększony zakres dla przychodów\n",
    "X, Y = np.meshgrid(axis_x, axis_y)\n",
    "\n",
    "# Przekształć siatkę punktów do formatu wymaganego przez model\n",
    "grid = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "Z = linear_reg_costs.predict(grid).reshape(X.shape)\n",
    "\n",
    "fig = plt.figure(facecolor='white', figsize=(10, 8))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_facecolor('white')\n",
    "\n",
    "# Wykreślenie danych treningowych i testowych\n",
    "ax.scatter(Z_train, P_train, C_train, label='Koszty prawdziwe(dane treningowe)', color='blue')\n",
    "ax.scatter(Z_test, P_test, C_test, label='Koszty prawdziwe(dane testowe)', color='green')\n",
    "\n",
    "# Wykreślenie powierzchni predykcji\n",
    "surf = ax.plot_surface(X, Y, Z, alpha=0.3, label='Predykcje kosztow', color='orange')\n",
    "surf._edgecolors2d = surf._edgecolor3d\n",
    "surf._facecolors2d = surf._facecolor3d\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Liczba pracownikow')\n",
    "ax.set_ylabel('Przychody [mln]')\n",
    "ax.set_zlabel('Koszty [mln]')\n",
    "plt.show()"
   ],
   "id": "df816f62b53f5fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T19:16:13.123196Z",
     "start_time": "2024-11-12T19:16:13.121170Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Funkcje do porownywania wydajnosci / sprawnosci modeli",
   "id": "42ff639530e930eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_models_comparison():\n",
    "\n",
    "    models = {\n",
    "        'Szereg czasowy': (train_metrics_0, test_metrics_0),\n",
    "        'Przychody': (train_metrics_1, test_metrics_1),\n",
    "        'Koszty': (train_metrics_2, test_metrics_2),\n",
    "        'Wielowymiarowy': (train_metrics_3, test_metrics_3)\n",
    "    }\n",
    "    \n",
    "    metrics = ['R2', 'MAPE']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        train_values = [m[0][metric] for m in models.values()]\n",
    "        test_values = [m[1][metric] for m in models.values()]\n",
    "        \n",
    "        x = np.arange(len(models))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[i].bar(x - width/2, train_values, width, label='Train')\n",
    "        axes[i].bar(x + width/2, test_values, width, label='Test')\n",
    "        \n",
    "        axes[i].set_title(f'{metric} dla różnych modeli')\n",
    "        axes[i].set_xticks(x)\n",
    "        axes[i].set_xticklabels(models.keys(), rotation=45)\n",
    "        axes[i].legend()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_models_comparison()"
   ],
   "id": "b9fabdc1bbb2170e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f42b3cf20aa94e4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_models_comparison():\n",
    "    models = {\n",
    "        'Szereg czasowy': (train_metrics_0, test_metrics_0),\n",
    "        'Przychody': (train_metrics_1, test_metrics_1),\n",
    "        'Koszty': (train_metrics_2, test_metrics_2),\n",
    "        'Wielowymiarowy': (train_metrics_3, test_metrics_3)\n",
    "    }\n",
    "    \n",
    "    # Zmieniamy zestaw metryk - usuwamy R2, dodajemy inne istotne metryki\n",
    "    metrics = ['MAPE', 'RMSE', 'MAE']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        train_values = [m[0][metric] for m in models.values()]\n",
    "        test_values = [m[1][metric] for m in models.values()]\n",
    "        \n",
    "        x = np.arange(len(models))\n",
    "        width = 0.35\n",
    "        \n",
    "        axes[i].bar(x - width/2, train_values, width, label='Train', color='skyblue')\n",
    "        axes[i].bar(x + width/2, test_values, width, label='Test', color='lightgreen')\n",
    "        \n",
    "        axes[i].set_title(f'{metric} dla różnych modeli')\n",
    "        axes[i].set_xticks(x)\n",
    "        axes[i].set_xticklabels(models.keys(), rotation=45)\n",
    "        axes[i].legend()\n",
    "        \n",
    "        # Dodanie etykiet z wartościami\n",
    "        for idx, value in enumerate(train_values):\n",
    "            axes[i].text(idx - width/2, value, f'{value:.2f}', \n",
    "                        ha='center', va='bottom')\n",
    "        for idx, value in enumerate(test_values):\n",
    "            axes[i].text(idx + width/2, value, f'{value:.2f}', \n",
    "                        ha='center', va='bottom')\n",
    "    \n",
    "    plt.suptitle('Porównanie metryk oceny jakości predykcji dla różnych modeli', \n",
    "                 fontsize=14, y=1.05)\n",
    "    \n",
    "    # Dodanie opisów metryk\n",
    "    fig.text(0.32, -0.1, 'MAPE - Średni błąd procentowy\\n(mniejszy = lepszy)', \n",
    "             ha='center', va='center')\n",
    "    fig.text(0.52, -0.1, 'RMSE - Pierwiastek błędu średniokwadratowego\\n(mniejszy = lepszy)', \n",
    "             ha='center', va='center')\n",
    "    fig.text(0.72, -0.1, 'MAE - Średni błąd bezwzględny\\n(mniejszy = lepszy)', \n",
    "             ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "b09c989788019f52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_models_comparison()",
   "id": "39df70152898d40f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_models_comparison_table():\n",
    "    models = {\n",
    "        'Szereg czasowy': (train_metrics_0, test_metrics_0),\n",
    "        'Przychody': (train_metrics_1, test_metrics_1),\n",
    "        'Koszty': (train_metrics_2, test_metrics_2),\n",
    "        'Wielowymiarowy': (train_metrics_3, test_metrics_3)\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPorównanie metryk dla wszystkich modeli:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Model':<15} {'Dane':<8} {'MAPE':>10} {'RMSE':>15} {'MAE':>15}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for model_name, (train_metrics, test_metrics) in models.items():\n",
    "        # Dane treningowe\n",
    "        print(f\"{model_name:<15} {'Train':<8} {train_metrics['MAPE']:10.2f} \"\n",
    "              f\"{train_metrics['RMSE']:15.2f} {train_metrics['MAE']:15.2f}\")\n",
    "        # Dane testowe\n",
    "        print(f\"{model_name:<15} {'Test':<8} {test_metrics['MAPE']:10.2f} \"\n",
    "              f\"{test_metrics['RMSE']:15.2f} {test_metrics['MAE']:15.2f}\")\n",
    "        print(\"-\" * 100)"
   ],
   "id": "f1e12de19533ead4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print_models_comparison_table()\n",
   "id": "e5a66e259eea229d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Redemption naszego modelu z 2 zmiennymi zaleznymi z logarytmizacja",
   "id": "202a9e7094d991f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Model z logarytmizacją wszystkich zmiennych\n",
    "# %matplotlib notebook\n",
    "# Przygotowanie danych\n",
    "Z_train_log = np.log10(Z_train)  # logarytm zatrudnienia\n",
    "P_train_log = np.log10(P_train)  # logarytm przychodów\n",
    "C_train_log = np.log10(C_train)  # logarytm kosztów\n",
    "ZP_train_log = np.column_stack((Z_train_log, P_train_log))\n",
    "\n",
    "Z_test_log = np.log10(Z_test)\n",
    "P_test_log = np.log10(P_test)\n",
    "C_test_log = np.log10(C_test)\n",
    "ZP_test_log = np.column_stack((Z_test_log, P_test_log))\n",
    "\n",
    "# Trenowanie modelu na zlogarytmowanych danych\n",
    "linear_reg_costs_log = LinearRegression()\n",
    "\n",
    "linear_reg_costs_log.fit(ZP_train_log, C_train_log)\n",
    "\n",
    "# Ocena modelu\n",
    "train_metrics_log = calculate_prediction_metrics(C_train_log, linear_reg_costs_log.predict(ZP_train_log))\n",
    "test_metrics_log = calculate_prediction_metrics(C_test_log, linear_reg_costs_log.predict(ZP_test_log))\n",
    "\n",
    "print_metrics_with_specific_units(train_metrics_log, \"Model kosztów (log) - trenowanie\", \"log10(mln $)\")\n",
    "print_metrics_with_specific_units(test_metrics_log, \"Model kosztów (log) - test\", \"log10(mln $)\")\n",
    "\n",
    "# Wizualizacja 3D dla modelu logarytmicznego\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Dane rzeczywiste\n",
    "scatter1 = ax.scatter(Z_train_log, P_train_log, C_train_log, \n",
    "                     c='blue', label='Treningowe')\n",
    "scatter2 = ax.scatter(Z_test_log, P_test_log, C_test_log, \n",
    "                     c='red', label='Testowe')\n",
    "\n",
    "# Powierzchnia predykcji\n",
    "x_range = np.linspace(Z_train_log.min(), Z_test_log.max(), 100)\n",
    "y_range = np.linspace(P_train_log.min(), P_test_log.max(), 100)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "XY = np.column_stack((X.ravel(), Y.ravel()))\n",
    "Z = linear_reg_costs_log.predict(XY).reshape(X.shape)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, alpha=0.3, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('log10(Zatrudnienie)')\n",
    "ax.set_ylabel('log10(Przychody)')\n",
    "ax.set_zlabel('log10(Koszty)')\n",
    "ax.legend()\n",
    "plt.title('Model kosztów w skali logarytmicznej')\n",
    "plt.show()\n",
    "\n",
    "# Retrieve the coefficients and intercept from the trained model\n",
    "a1 = linear_reg_costs_log.coef_[0][0]\n",
    "a2 = linear_reg_costs_log.coef_[0][1]\n",
    "b = linear_reg_costs_log.intercept_[0]\n",
    "\n",
    "# Print the full equation of the model\n",
    "print(f\"Model H = {a1} * log10(Z) + {a2} * log10(P) + {b}\")"
   ],
   "id": "e1d53dcb7d425616",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2. Model z normalizacją danych\n",
    "# Przygotowanie danych\n",
    "scaler_Z = StandardScaler()\n",
    "scaler_P = StandardScaler()\n",
    "scaler_C = StandardScaler()\n",
    "\n",
    "Z_train_norm = scaler_Z.fit_transform(Z_train)\n",
    "P_train_norm = scaler_P.fit_transform(P_train)\n",
    "C_train_norm = scaler_C.fit_transform(C_train)\n",
    "ZP_train_norm = np.column_stack((Z_train_norm, P_train_norm))\n",
    "\n",
    "Z_test_norm = scaler_Z.transform(Z_test)\n",
    "P_test_norm = scaler_P.transform(P_test)\n",
    "C_test_norm = scaler_C.transform(C_test)\n",
    "ZP_test_norm = np.column_stack((Z_test_norm, P_test_norm))\n",
    "\n",
    "# Trenowanie modelu na znormalizowanych danych\n",
    "linear_reg_costs_norm = LinearRegression()\n",
    "linear_reg_costs_norm.fit(ZP_train_norm, C_train_norm)\n",
    "\n",
    "# Ocena modelu\n",
    "train_metrics_norm = calculate_prediction_metrics(C_train_norm, \n",
    "                                               linear_reg_costs_norm.predict(ZP_train_norm))\n",
    "test_metrics_norm = calculate_prediction_metrics(C_test_norm, \n",
    "                                              linear_reg_costs_norm.predict(ZP_test_norm))\n",
    "\n",
    "print_metrics_with_specific_units(train_metrics_norm, \n",
    "                                \"Model kosztów (normalized) - trenowanie\", \n",
    "                                \"znormalizowane jednostki\")\n",
    "print_metrics_with_specific_units(test_metrics_norm, \n",
    "                                \"Model kosztów (normalized) - test\", \n",
    "                                \"znormalizowane jednostki\")"
   ],
   "id": "495fce7b18610c1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# 3. Model z cechami wielomianowymi\n",
    "# Przygotowanie danych\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "ZP_train_poly = poly.fit_transform(ZP_train_norm)  # używamy znormalizowanych danych\n",
    "ZP_test_poly = poly.transform(ZP_test_norm)\n",
    "\n",
    "# Trenowanie modelu\n",
    "linear_reg_costs_poly = LinearRegression()\n",
    "linear_reg_costs_poly.fit(ZP_train_poly, C_train_norm)\n",
    "\n",
    "# Ocena modelu\n",
    "train_metrics_poly = calculate_prediction_metrics(C_train_norm, \n",
    "                                               linear_reg_costs_poly.predict(ZP_train_poly))\n",
    "test_metrics_poly = calculate_prediction_metrics(C_test_norm, \n",
    "                                              linear_reg_costs_poly.predict(ZP_test_poly))\n",
    "\n",
    "print_metrics_with_specific_units(train_metrics_poly, \n",
    "                                \"Model kosztów (polynomial) - trenowanie\", \n",
    "                                \"znormalizowane jednostki\")\n",
    "print_metrics_with_specific_units(test_metrics_poly, \n",
    "                                \"Model kosztów (polynomial) - test\", \n",
    "                                \"znormalizowane jednostki\")\n",
    "\n",
    "# linear_reg_costs_poly.coef_?? \n",
    "# ?linear_reg_costs_poly.coef_\n",
    "# ??linear_reg_costs_poly.coef"
   ],
   "id": "c06aa92ede8ab745",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
