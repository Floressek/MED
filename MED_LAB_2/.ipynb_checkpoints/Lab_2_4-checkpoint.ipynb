{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lab 2.4: Platki sniadaniowe - klasyfikacja",
   "id": "c142a0fee0e7e9d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Paczki i dane",
   "id": "2a01f715c2df36e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Basic paczki do analizy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Paczki do klasyfikacji i modelowania\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Klasyfikatory\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "if not os.path.exists('Płatki-sniadaniowe-cereals.txt'):\n",
    "    raise FileNotFoundError(\"Plik 'Płatki-sniadaniowe-cereals.txt' nie został znaleziony.\")"
   ],
   "id": "33b0695c2cacc70f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ustawienia dla wykresów\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "# Wczytanie danych\n",
    "df = pd.read_csv('Płatki-sniadaniowe-cereals.txt', sep='\\t')\n",
    "\n",
    "# Definicja zmiennych do analizy\n",
    "nutrients = ['kalorie', 'cukry', 'weglowodany', 'proteiny', 'tluszcz', 'blonnik', 'sod', 'potas']\n",
    "nutrient_names = ['Kalorie', 'Cukry', 'Węglowodany', 'Proteiny', 'Tłuszcz', 'Błonnik', 'Sód', 'Potas']"
   ],
   "id": "c501a0715be04c05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analiza danych - wykresy\n",
   "id": "e57178d6dd04128c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykresy skrzypcowe",
   "id": "d8c2c8e93c167b8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_detailed_violin_plots():\n",
    "    # Tworzymy osobny wykres dla każdej półki\n",
    "    for shelf in sorted(df['Liczba_polek'].unique()):\n",
    "        shelf_data = df[df['Liczba_polek'] == shelf]\n",
    "\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, (nutrient, name) in enumerate(zip(nutrients, nutrient_names)):\n",
    "            plt.subplot(2, 4, i + 1)\n",
    "            sns.violinplot(y=nutrient, data=shelf_data, inner='box')\n",
    "            plt.title(f'{name} - Półka {shelf}')\n",
    "            plt.ylabel('Wartość')\n",
    "\n",
    "        plt.suptitle(f'Rozkłady składników odżywczych dla półki {shelf}', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "create_detailed_violin_plots()"
   ],
   "id": "f8e1e81e48986053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Wykresy radarowe dla profilu odżywczego kazdej półki\n",
    "\n"
   ],
   "id": "ea6932cb154c89bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_radar_plots() -> None:\n",
    "    # Tworzymy osobne wykresy dla każdej półki\n",
    "    shelf_means = df.groupby('Liczba_polek')[nutrients].mean()\n",
    "\n",
    "    # Normalizacja danych do 0,1 bo skala wartości jest różna\n",
    "    shelf_means_norm = (shelf_means - shelf_means.min()) / (shelf_means.max() - shelf_means.min())\n",
    "\n",
    "    # Linespace tworzy równo odległe wartości w zadanym przedziale\n",
    "    angles = np.linspace(0, 2 * np.pi, len(nutrients), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))  # Zamknięcie pętli\n",
    "\n",
    "    for shelf in sorted(df['Liczba_polek'].unique()):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "        values = shelf_means_norm.loc[shelf].values\n",
    "        values = np.concatenate((values, [values[0]]))  # Konkatenacja ktora zamyka pętlę\n",
    "\n",
    "        # Rysowanie wykresu\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=f'Półka {shelf}')\n",
    "        ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "        # Ustawienie nazw osi\n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(nutrient_names)\n",
    "\n",
    "        plt.title(f'Profil odżywczy - Półka {shelf}')\n",
    "\n",
    "        # Dodanie oryginalnych wartości\n",
    "        orig_values = shelf_means.loc[shelf].round(1)\n",
    "        legend_text = '\\n'.join([f'{name}: {value}'\n",
    "                                 for name, value in zip(nutrient_names, orig_values)])\n",
    "        plt.figtext(1.1, 0.5, f'Wartości średnie:\\n\\n{legend_text}',\n",
    "                    bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "create_radar_plots()"
   ],
   "id": "9e8e0fdaf1fa6c67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analiza skladu wedlug producenta - top 5\n",
   "id": "6f146db8449901d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_by_manufacturer() -> None:\n",
    "    # Grupowanie po producencie\n",
    "    manufacturers = df['producent'].value_counts().head(5).index  # 5 najczęstszych producentów\n",
    "    df_filtered = df[df['producent'].isin(manufacturers)]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (nutrient, name) in enumerate(zip(nutrients, nutrient_names)):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        box_plot = sns.boxplot(x='producent', y=nutrient, data=df_filtered)\n",
    "        plt.title(f'{name} - według producenta')\n",
    "        plt.ylabel('Wartość')\n",
    "        plt.xlabel('Producent')\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.suptitle('Rozkłady składników odżywczych dla producentów', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "analyze_by_manufacturer()"
   ],
   "id": "5c644fde87cc428d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Heatmapa srednich wartosci",
   "id": "b78f7f95c17dabb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_nutrient_heatmap() -> None:\n",
    "    shelf_means = df.groupby('Liczba_polek')[nutrients].mean()\n",
    "    shelf_means_normalized = (shelf_means - shelf_means.mean()) / shelf_means.std()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(shelf_means_normalized.T,\n",
    "                annot=shelf_means.T.round(1),\n",
    "                fmt='.1f',\n",
    "                cmap='RdYlBu_r',\n",
    "                center=0)\n",
    "    plt.title('Średnie wartości składników odżywczych\\n - kolory pokazuja znormalizowane wartosci')\n",
    "    plt.xlabel('Numer półki')\n",
    "    plt.ylabel('Składnik odżywczy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "create_nutrient_heatmap()"
   ],
   "id": "eef3b03e8949091a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykresy przedzialow srednich wartosci dla polek z 95% przedzialem ufności",
   "id": "af5d09f4c6d8018e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_confidence_intervals() -> None:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, (nutrient, name) in enumerate(zip(nutrients, nutrient_names)):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        sns.barplot(x='Liczba_polek', y=nutrient, data=df, ci=95)\n",
    "        plt.title(f'Średnia {name} z 95% przedziałem ufności')\n",
    "        plt.xlabel('Numer półki')\n",
    "        plt.ylabel(name)\n",
    "    plt.suptitle('Średnie wartości składników z przedziałami ufności', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confidence_intervals()"
   ],
   "id": "be12801d69676d4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analiza korelacji miedzy potencjalnymi zmiennymi niezaleznymi",
   "id": "49ef807d21850df7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_correlation_analysis() -> None:\n",
    "    corr_matrix = df[nutrients].corr()  # Macierz korelacji\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = np.triu(np.ones_like(corr_matrix), k=1)  # Maskowanie górnej trójkątnej macierzy\n",
    "    sns.heatmap(corr_matrix,\n",
    "                mask=mask,\n",
    "                annot=True,\n",
    "                cmap='coolwarm',\n",
    "                vmin=-1,  # Skala korelacji od -1 do 1 \n",
    "                vmax=1,\n",
    "                center=0)\n",
    "    plt.title('Macierz korelacji między składnikami odżywczymi')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_correlation_analysis()"
   ],
   "id": "ce2e10d017da1b11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analiza statystyczna - testy statystyczne np. dla P-value",
   "id": "abc5d22a406f38e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def detailed_statistical_analysis() -> None:\n",
    "    print(\"\\nSzczegółowa analiza statystyczna składników:\")\n",
    "\n",
    "    for nutrient, name in zip(nutrients, nutrient_names):\n",
    "        print(f\"\\n{name}:\")\n",
    "\n",
    "        # Statystyki opisowe\n",
    "        stats_by_shelf = (df.groupby('Liczba_polek')[nutrient]\n",
    "                          .agg(['count', 'mean', 'std', 'min', 'max']))\n",
    "        print(\"\\nStatystyki według półek:\")\n",
    "        print(stats_by_shelf.round(2))\n",
    "\n",
    "        # Test Kruskal-Wallis\n",
    "        groups = [group for _, group in df.groupby('Liczba_polek')[nutrient]]\n",
    "        h_stat, p_val = stats.kruskal(*groups)\n",
    "        print(f\"\\nTest Kruskal-Wallis:\")\n",
    "        print(f\"H-statistic = {h_stat:.2f}\")\n",
    "        print(f\"p-value = {p_val:.4f}\")\n",
    "\n",
    "\n",
    "detailed_statistical_analysis()"
   ],
   "id": "4514a819a32a5c96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Podsumowanie analiz\n",
    "print(\"\\nPodstawowe wnioski z analizy:\")\n",
    "for nutrient in nutrients:\n",
    "    shelf_means = df.groupby('Liczba_polek')[nutrient].mean()  # Średnie wartości składników\n",
    "    max_shelf = shelf_means.idxmax()\n",
    "    min_shelf = shelf_means.idxmin()\n",
    "    diff_percent = ((shelf_means[max_shelf] - shelf_means[min_shelf]) / shelf_means[min_shelf] * 100).round(2)\n",
    "\n",
    "    print(f\"\\n{nutrient.capitalize()}:\")\n",
    "    print(f\"- Różnica między półkami: {diff_percent:.1f}%\")\n",
    "    print(f\"- Najwyższa średnia (półka {max_shelf}): {shelf_means[max_shelf]:.2f}\")\n",
    "    print(f\"- Najniższa średnia (półka {min_shelf}): {shelf_means[min_shelf]:.2f}\")"
   ],
   "id": "804af07c10eb1e83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Klasyfikator dla polki srodkowej oraz dla wszystkich pol, metodami: \n",
    "#### - KNN\n",
    "#### - Naive Bayes\n",
    "#### - Random Forest"
   ],
   "id": "c958de46018fa713"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Kalkulator metryki danego klasyfikatora - funckja pomocnicza",
   "id": "3bee04d583e74d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_metrics(conf_matrix: np.ndarray, model_name=\"\") -> dict:\n",
    "    \"\"\"\n",
    "    Oblicza i wyświetla wszystkie metryki dla danego klasyfikatora\n",
    "    \"\"\"\n",
    "\n",
    "    # Wyciągnięcie wartości z macierzy\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "    # Basic metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # precyzja\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # czułość\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # swoistość\n",
    "\n",
    "    # F1 score mowi nam o zbalansowaniu pomiedzy precyzja i czułością\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    # Advanced metrics\n",
    "    # Matthews Correlation Coefficient (MCC) mowi nam o zależności pomiedzy obserwowanymi i przewidywanymi wartościami\n",
    "    mcc_numerator = (TP * TN) - (FP * FN)  # licznik współczynnika korelacji Matthews\n",
    "    mcc_denominator = np.sqrt(\n",
    "        (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))  # mianownik współczynnika korelacji Matthews\n",
    "    mcc = mcc_numerator / mcc_denominator if mcc_denominator != 0 else 0\n",
    "\n",
    "    balanced_accuracy = (recall + specificity) / 2  # zbalansowana dokładność\n",
    "    informedness = recall + specificity - 1  # informacyjność\n",
    "    markedness = precision + specificity - 1 if specificity > 0 else 0  # znakowność\n",
    "\n",
    "    print(f\"\\n=== Metryki klasyfikacji {model_name} ===\")\n",
    "    print(f\"Podstawowe metryki:\")\n",
    "    print(f\"- Dokładność (Accuracy) = {accuracy:.3f}\")\n",
    "    print(f\"- Precyzja (Precision) = {precision:.3f}\")\n",
    "    print(f\"- Czułość (Recall/Sensitivity) = {recall:.3f}\")\n",
    "    print(f\"- Swoistość (Specificity) = {specificity:.3f}\")\n",
    "    print(f\"- F1 Score = {f1_score:.3f}\")\n",
    "\n",
    "    print(f\"\\nZaawansowane metryki:\")\n",
    "    print(f\"- Matthews Correlation Coefficient (MCC) = {mcc:.3f}\")\n",
    "    print(f\"- Balanced Accuracy = {balanced_accuracy:.3f}\")\n",
    "    print(f\"- Informedness (Youden's J) = {informedness:.3f}\")\n",
    "    print(f\"- Markedness = {markedness:.3f}\")\n",
    "\n",
    "    print(f\"\\nWartości macierzy pomyłek:\")\n",
    "    print(f\"- True Negatives (TN) = {TN}\")\n",
    "    print(f\"- False Positives (FP) = {FP}\")\n",
    "    print(f\"- False Negatives (FN) = {FN}\")\n",
    "    print(f\"- True Positives (TP) = {TP}\")\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'mcc': mcc,\n",
    "        'balanced_accuracy': balanced_accuracy\n",
    "    }\n"
   ],
   "id": "22bb71e984df474a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('Płatki-sniadaniowe-cereals.txt', sep='\\t')\n",
    "\n",
    "print(\"=== Analiza danych wejściowych ===\")\n",
    "print(f\"\\nLiczba produktów: {len(df)}\")\n",
    "print(\"\\nRozkład produktów na półkach:\")\n",
    "print(df[['polka_1', 'polka_2', 'polka_3']].sum())"
   ],
   "id": "7c33f60dcdcdafb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper do trenowania i ewaluacji klasyfikatora",
   "id": "7cf3a8807a35fee9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_and_evaluate_classifier(clf, X: np.ndarray, y: np.ndarray, classifier_name: str,\n",
    "                                  is_simple_model=False):  # is_simple_model - model proponowany na podstawie wstepnej analizy danych\n",
    "    \"\"\"\n",
    "    Trenuje i ewaluuje klasyfikator, zwraca metryki\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cross-validation\n",
    "        scores = cross_val_score(clf, X, y, cv=5)  # 5-krotna walidacja krzyżowa\n",
    "        print(\n",
    "            f\"\\nWyniki walidacji krzyżowej dla klasyfikatora {classifier_name}: {scores.mean():.3f} (±{scores.std():.3f})\")\n",
    "\n",
    "        clf.fit(X, y)  # Trenowanie klasyfikatora\n",
    "        y_pred = clf.predict(X)  # Predykcja\n",
    "\n",
    "        # Obliczanie metryk\n",
    "        print(f\"\\n=== Wyniki klasyfikacji dla {classifier_name} ===\")\n",
    "        print(classification_report(y, y_pred))\n",
    "\n",
    "        conf_matrix = confusion_matrix(y, y_pred)\n",
    "        metrics = calculate_metrics(conf_matrix, classifier_name)\n",
    "\n",
    "        if is_simple_model:\n",
    "            # Wizualizacja macierzy pomyłek\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            df_cm = pd.DataFrame(conf_matrix,\n",
    "                                 index=['Nie na środkowej', 'Na środkowej'],\n",
    "                                 columns=['Przewidziano: Nie', 'Przewidziano: Tak']\n",
    "                                 )\n",
    "            sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Macierz pomyłek dla klasyfikatora {classifier_name}')\n",
    "            plt.ylabel('Prawdizwa wartość')\n",
    "            plt.xlabel('Przewidywana wartość')\n",
    "            plt.show()\n",
    "\n",
    "        return clf, metrics  # Zwracamy klasyfikator i metryki\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd podczas trenowania {classifier_name}: {str(e)}\")\n",
    "        return clf, None  # Zwracamy None w przypadku błędu"
   ],
   "id": "786f540ba77bedfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 1: Klasyfikacja dla półki środkowej",
   "id": "fd57f074b92dda6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Model 1: Klasyfikacja dla półki środkowej (cukier i kalorie) ===\")\n",
    "X_simple = df[['cukry', 'kalorie']]\n",
    "y_middle = (df['polka_2'] == 1).astype(int)  # Klasyfikacja dla półki środkowej\n",
    "\n",
    "# Standaryzacja danych \n",
    "scaler_simple = StandardScaler()\n",
    "scaler_simple.fit(X_simple)\n",
    "X_simple_scaled = scaler_simple.transform(X_simple)\n",
    "\n",
    "# Inicjalizacja klasyfikatorów\n",
    "classifiers_simple = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Trenowanie i ewaulacja klasyfikatora dla prostego modelu\n",
    "results_simple = {}\n",
    "for name, clf in classifiers_simple.items():\n",
    "    print(f\"\\n=== Klasyfikator: {name} ===\")\n",
    "    trained_clf, metrics = train_and_evaluate_classifier(clf,\n",
    "                                                         X_simple_scaled,\n",
    "                                                         y_middle,\n",
    "                                                         f\"{name} (Model 1 - środkowa półka)\",\n",
    "                                                         is_simple_model=True\n",
    "                                                         )\n",
    "    results_simple[name] = metrics\n"
   ],
   "id": "fcd667e428a469e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja porównawcza dla prostego modelu (środkowa półka). Prosty model czyli ten gdzie to MY wybieramy zmienne niezalezne ",
   "id": "65dd0005a6ff50d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wizualizacja porównawcza dla prostego modelu (środkowa półka)\n",
    "metrics_to_plot = ['accuracy', 'f1_score', 'balanced_accuracy']\n",
    "metrics_labels = ['Dokładność', 'F1 Score', 'Zbalansowana dokładność']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(metrics_to_plot))\n",
    "width = 0.25\n",
    "\n",
    "for i, (clf_name, metrics) in enumerate(results_simple.items()):\n",
    "    values = [metrics[metric] for metric in metrics_to_plot]\n",
    "    plt.bar(x + i * width, values, width, label=clf_name)\n",
    "\n",
    "plt.xlabel('Metryka')\n",
    "plt.ylabel('Wartość')\n",
    "plt.title('Porównanie klasyfikatorów dla środkowej półki (Model 1)')\n",
    "plt.xticks(x + width, metrics_labels)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6e3a95adfffcfbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 2: Klasyfikacja dla wszystkich polek i wybor optymalny cech",
   "id": "ae853025f5389551"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Model 2: Klasyfikacja dla poszczególnych półek ===\")\n",
    "features = ['kalorie', 'cukry', 'weglowodany', 'proteiny', 'tluszcz', 'blonnik', 'sod', 'potas']\n",
    "X_full = df[features]\n",
    "scaler_full = StandardScaler()\n",
    "scaler_full.fit(X_full)\n",
    "X_full_scaled = scaler_full.transform(X_full)  # Standaryzacja danych\n",
    "\n",
    "# Inicjalizacja klasyfikatorów\n",
    "results_full = {'polka_1': {}, 'polka_2': {}, 'polka_3': {}}\n",
    "\n",
    "# Analiza kazdej polki z osobna\n",
    "for shelf_num, shelf in enumerate(['polka_1', 'polka_2', 'polka_3'], 1):\n",
    "    print(f\"\\n=== Analiza półki {shelf_num} ===\")\n",
    "    y_shelf = (df[shelf] == 1).astype(int)  # Klasyfikacja dla danej półki\n",
    "\n",
    "    # Wybor cech za pomoca Random Forest\n",
    "    selector = SelectFromModel(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "    selector.fit(X_full_scaled, y_shelf)  # Trenowanie modelu\n",
    "    selected_mask = selector.get_support()  # Wybor cech \n",
    "\n",
    "    # Wyswietlenie wybranych cech\n",
    "    selected_features = [feat for feat, selected in zip(features, selected_mask) if selected]\n",
    "    # tlumaczenie tego fora to: dla kazdego elementu w features i selected_mask jesli selected to dodaj do listy\n",
    "    print(f\"Wybrane cechy dla półki {shelf_num}: {selected_features}\")\n",
    "\n",
    "    # Trenowanie i ewaluacja klasyfikatora \n",
    "    X_selected = X_full_scaled[:, selected_mask]  # Wybranie cech\n",
    "    for name in classifiers_simple.keys():\n",
    "        if name == 'Random Forest':\n",
    "            clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "        elif name == 'k-NN':\n",
    "            clf = KNeighborsClassifier(n_neighbors=5)\n",
    "        else:  # Naive Bayes\n",
    "            clf = GaussianNB()\n",
    "\n",
    "        print(f\"\\n=== Klasyfikator: {name} ===\")\n",
    "        trained_clf, metrics = train_and_evaluate_classifier(\n",
    "            clf,\n",
    "            X_selected,\n",
    "            y_shelf,\n",
    "            f\"{name} (Model 2 - półka {shelf_num})\"\n",
    "        )\n",
    "        if metrics is not None:  # Dodajemy sprawdzenie\n",
    "            results_full[shelf][name] = metrics\n",
    "        else:\n",
    "            print(f\"Pominięto wyniki dla {name} na półce {shelf_num} z powodu błędu\")"
   ],
   "id": "866db3f2c9befaca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja porównawcza dla wszystkich półek (Model 2)",
   "id": "f6a6acfe54b7c38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wizualizacja porównawcza dla wszystkich półek (Model 2)\n",
    "for metric in metrics_to_plot:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(results_full))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, clf_name in enumerate(classifiers_simple.keys()):\n",
    "        values = [results_full[shelf][clf_name][metric] for shelf in results_full]\n",
    "        plt.bar(x + i * width, values, width, label=clf_name)\n",
    "    \n",
    "    plt.xlabel('Półka')\n",
    "    plt.ylabel(f'{metrics_labels[metrics_to_plot.index(metric)]}')\n",
    "    plt.title(f'Porównanie klasyfikatorów dla wszystkich półek - {metrics_labels[metrics_to_plot.index(metric)]}')\n",
    "    plt.xticks(x + width, ['Półka 1', 'Półka 2', 'Półka 3'])\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "561a83d618056520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Podsumowanie wynikow tekstowe",
   "id": "e3fc1635976f67a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Podsumowanie wyników\n",
    "print(\"\\n=== Podsumowanie wyników ===\")\n",
    "\n",
    "print(\"\\n++ Model 1 (Środkowa półka): ++\")\n",
    "for clf_name, metrics in results_simple.items():\n",
    "    print(f\"\\n{clf_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"- {metric}: {value:.3f}\")\n",
    "\n",
    "print(\"\\n++ Model 2 (Wszystkie półki): ++\")\n",
    "for shelf in results_full:\n",
    "    print(f\"\\nPółka {shelf}:\")\n",
    "    for clf_name, metrics in results_full[shelf].items():\n",
    "        print(f\"\\n{clf_name}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"- {metric}: {value:.3f}\")"
   ],
   "id": "5931f297d1a54c54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja macierzy pomyłek dla wszystkich klasyfikatorów",
   "id": "68d8454cd115f2d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wizualizacja macierzy pomyłek dla wszystkich klasyfikatorów\n",
    "def plot_confusion_matrices():\n",
    "    for shelf_num, shelf in enumerate(['polka_1', 'polka_2', 'polka_3'], 1):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, (clf_name, metrics) in enumerate(results_full[shelf].items(), 1):\n",
    "            y_shelf = (df[shelf] == 1).astype(int)\n",
    "            \n",
    "            if clf_name == 'Random Forest':\n",
    "                clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "            elif clf_name == 'KNN':\n",
    "                clf = KNeighborsClassifier(n_neighbors=5)\n",
    "            else:  # Naive Bayes\n",
    "                clf = GaussianNB()\n",
    "            \n",
    "            # Wybór cech\n",
    "            selector = SelectFromModel(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "            selector.fit(X_full_scaled, y_shelf)\n",
    "            selected_mask = selector.get_support()\n",
    "            X_selected = X_full_scaled[:, selected_mask]\n",
    "            \n",
    "            # Trenowanie i predykcja\n",
    "            clf.fit(X_selected, y_shelf)\n",
    "            y_pred = clf.predict(X_selected)\n",
    "            conf_matrix = confusion_matrix(y_shelf, y_pred)\n",
    "            \n",
    "            # Wizualizacja macierzy pomyłek\n",
    "            plt.subplot(1, 3, i)\n",
    "            df_cm = pd.DataFrame(\n",
    "                conf_matrix,\n",
    "                index=['Nie na półce', 'Na półce'],\n",
    "                columns=['Przewidziano: Nie', 'Przewidziano: Tak']\n",
    "            )\n",
    "            sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Macierz pomyłek - {clf_name}\\nPółka {shelf_num}')\n",
    "            plt.ylabel('Prawdziwa wartość')\n",
    "            plt.xlabel('Przewidywana wartość')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Generowanie wszystkich wizualizacji\n",
    "print(\"=== Macierze pomyłek dla wszystkich klasyfikatorów ===\")\n",
    "plot_confusion_matrices()"
   ],
   "id": "1c729ba273892592",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wizualizacja wag zmiennych",
   "id": "8a03ca5dc45251b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_feature_importance():\n",
    "    for shelf_num, shelf in enumerate(['polka_1', 'polka_2', 'polka_3'], 1):\n",
    "        y_shelf = (df[shelf] == 1).astype(int)\n",
    "        \n",
    "        # # Random Forest feature importance\n",
    "        # rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "        # rf.fit(X_full_scaled, y_shelf)\n",
    "        \n",
    "        # Wybór cech\n",
    "        selector = SelectFromModel(RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "        selector.fit(X_full_scaled, y_shelf)\n",
    "        selected_mask = selector.get_support()\n",
    "        \n",
    "        # Tylko wybrane cechy\n",
    "        selected_features = [feat for feat, selected in zip(features, selected_mask) if selected]\n",
    "        \n",
    "        # Random Forest tylko na wybranych cechach\n",
    "        rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "        rf.fit(X_full_scaled[:, selected_mask], y_shelf)\n",
    "        \n",
    "        # Wizualizacja\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'cecha': selected_features,\n",
    "            'waga': rf.feature_importances_\n",
    "        })\n",
    "        feature_importance = feature_importance.sort_values('waga', ascending=False)\n",
    "        sns.barplot(data=feature_importance, x='cecha', y='waga')\n",
    "        plt.title(f'Ważność cech dla półki {shelf_num} (Random Forest)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "print(\"\\n=== Ważność cech dla każdej półki ===\")\n",
    "plot_feature_importance()"
   ],
   "id": "6234228eb00f612b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Wykres rozmieszczenia płatków z prawdopodobieństwem",
   "id": "c1110548af72484d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_decision_boundary():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Granice decyzyjne dla Random Forest\n",
    "    x_min, x_max = X_simple['cukry'].min() - 1, X_simple['cukry'].max() + 1 # -1 i +1 to margines\n",
    "    y_min, y_max = X_simple['kalorie'].min() - 10, X_simple['kalorie'].max() + 10 # -10 i +10 to margines\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.5), # 0.5 to krok\n",
    "                         np.arange(y_min, y_max, 2)) # 2 to krok\n",
    "    \n",
    "    # Standaryzacja danych\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()] # Ravel - splaszczanie tablicy\\\n",
    "    grid_points_scaled = scaler_simple.transform(grid_points) # Standaryzacja danych\n",
    "    \n",
    "    # Predykcja dla każdego punktu\n",
    "    rf = classifiers_simple['Random Forest']\n",
    "    Z = rf.predict_proba(grid_points_scaled)[:, 1]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Mapa decyzyjna\n",
    "    plt.contourf(xx, yy, Z, levels=np.linspace(0, 1, 11), alpha=0.6, cmap='RdYlBu')\n",
    "    plt.colorbar(label='Prawdopodobieństwo środkowej półki')\n",
    "    \n",
    "    # Punkty danych\n",
    "    plt.scatter(X_simple['cukry'][y_middle == 0], X_simple['kalorie'][y_middle == 0],\n",
    "                c='red', label='Inna półka', alpha=0.8)\n",
    "    plt.scatter(X_simple['cukry'][y_middle == 1], X_simple['kalorie'][y_middle == 1], \n",
    "                c='blue', label='Środkowa półka', alpha=0.8)\n",
    "    \n",
    "    # Etykiety produktów\n",
    "    for i, row in df.iterrows():\n",
    "        point_scaled = scaler_simple.transform([[row['cukry'], row['kalorie']]])\n",
    "        prob = rf.predict_proba(point_scaled)[0][1]\n",
    "        if prob > 0.7 or prob < 0.3:\n",
    "            plt.annotate(row['nazwa'],\n",
    "                         (row['cukry'], row['kalorie']),\n",
    "                         xytext=(5, 5),\n",
    "                         textcoords='offset points',\n",
    "                         fontsize=8,\n",
    "                         bbox=dict(facecolor='white', edgecolor='none', alpha=0.7))\n",
    "    \n",
    "    plt.xlabel('Zawartość cukru (g)')\n",
    "    plt.ylabel('Kalorie')\n",
    "    plt.title('Klasyfikacja produktów na środkowej półce (Random Forest)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n=== Mapa decyzyjna dla klasyfikacji środkowej półki ===\")\n",
    "plot_decision_boundary()"
   ],
   "id": "94f79f3d65bbdea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "77abe09d159dc1d3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
